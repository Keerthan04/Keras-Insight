{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pinecone Vector Store Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langchain\n",
    "!pip install langchain-core\n",
    "!pip install langchain-community\n",
    "!pip install langchain-pinecone\n",
    "!pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize pinecone vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import userdata\n",
    "pinecone_api_key = userdata.get('pinecone_api_key')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import Pinecone, ServerlessSpec\n",
    "import time\n",
    "# from config import VECTOR_DIMENSION\n",
    "VECTOR_DIMENSION = 384 # 768 do if nomic embeddings using\n",
    "class PineconeManager:\n",
    "    def __init__(self, api_key: str, index_name: str):\n",
    "        self.pc = Pinecone(api_key=api_key)\n",
    "        self.index_name = index_name\n",
    "        self.index = None\n",
    "        self.initialize_index() #to initialize the index\n",
    "    def initialize_index(self):\n",
    "        if self.index_name not in self.pc.list_indexes().names():#shd use list indexes here\n",
    "            print(f\"Creating index: {self.index_name}\")\n",
    "            self.pc.create_index(\n",
    "                name=self.index_name,\n",
    "                dimension=VECTOR_DIMENSION,\n",
    "                metric=\"cosine\",\n",
    "                spec=ServerlessSpec(\n",
    "                    cloud=\"aws\",\n",
    "                    region=\"us-east-1\"\n",
    "                )\n",
    "            )\n",
    "        else:\n",
    "            print(f\"Index {self.index_name} already exists\")\n",
    "\n",
    "        while not self.pc.describe_index(self.index_name).status['ready']:\n",
    "            time.sleep(1)\n",
    "\n",
    "        self.index = self.pc.Index(self.index_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INDEX_NAME = 'dlprojectcheck'\n",
    "pinecone_manager = PineconeManager(pinecone_api_key, INDEX_NAME)\n",
    "pinecone_manager.initialize_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scraping and inseting into VectorStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import asyncio\n",
    "import aiohttp\n",
    "from bs4 import BeautifulSoup\n",
    "from typing import List, Dict\n",
    "from langchain.docstore.document import Document\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "class WebScraper:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    @staticmethod\n",
    "    async def extract_sections(soup: BeautifulSoup) -> List[Dict[str, str]]:\n",
    "        \"\"\"Extract sections from a parsed HTML page.\n",
    "\n",
    "        Sections are defined as the contents between headers (h1, h2, h3) and are\n",
    "        dictionaries with keys \"title\", \"content\", and \"code\". The value of \"title\"\n",
    "        is the text of the header, \"content\" is the text content of the section, and\n",
    "        \"code\" is the code blocks in the section.\n",
    "\n",
    "        :param soup: A BeautifulSoup object representing the HTML page\n",
    "        :return: A list of section dictionaries\n",
    "        \"\"\"\n",
    "        sections = []\n",
    "        current_section = {\"title\": \"Introduction\", \"content\": \"\", \"code\": \"\"}\n",
    "\n",
    "        for element in soup.find_all(['h1', 'h2', 'h3', 'p', 'pre']):\n",
    "            if element.name in ['h1', 'h2', 'h3']:\n",
    "                if current_section[\"content\"] or current_section[\"code\"]:\n",
    "                    sections.append(current_section)\n",
    "                current_section = {\"title\": element.get_text(strip=True), \"content\": \"\", \"code\": \"\"}\n",
    "            elif element.name == 'p':\n",
    "                current_section[\"content\"] += element.get_text(strip=True) + \"\\n\"\n",
    "            elif element.name == 'pre':\n",
    "                code = element.find('code')\n",
    "                if code:\n",
    "                    current_section[\"code\"] += code.get_text(strip=True) + \"\\n\\n\"\n",
    "\n",
    "        if current_section[\"content\"] or current_section[\"code\"]:\n",
    "            sections.append(current_section)\n",
    "\n",
    "        return sections\n",
    "\n",
    "    def create_documents(self, sections: List[Dict[str, str]], file_path: str) -> List[Document]:\n",
    "        \"\"\"Create a list of Document objects from a list of sections and a file path.\n",
    "\n",
    "        The content of each section is combined with its code block (if any) and\n",
    "        used to create a Document object. The metadata of the Document includes\n",
    "        the title of the section and the source file path.\n",
    "\n",
    "        :param sections: A list of dictionaries with keys \"title\", \"content\", and \"code\"\n",
    "        :param file_path: The path to the file containing the sections\n",
    "        :return: A list of Document objects\n",
    "        \"\"\"\n",
    "        documents = []\n",
    "        for section in sections:\n",
    "            content = section[\"content\"]\n",
    "            code = section[\"code\"]\n",
    "            combined_text = f\"{content}\\n\\nCode:\\n{code}\"\n",
    "\n",
    "            document = Document(\n",
    "                page_content=combined_text,\n",
    "                metadata={\n",
    "                    \"title\": section[\"title\"],\n",
    "                    \"source\": file_path\n",
    "                }\n",
    "            )\n",
    "            documents.append(document)\n",
    "        \n",
    "        return documents\n",
    "\n",
    "    async def scrape_file(self, file_path: str) -> List[Document]:\n",
    "        \"\"\"Scrape a file and return a list of Document objects.\n",
    "\n",
    "        The file is read and parsed with BeautifulSoup, and then the sections\n",
    "        are extracted and combined into Document objects. The metadata of each\n",
    "        Document includes the title of the section and the source file path.\n",
    "\n",
    "        :param file_path: The path to the file to scrape\n",
    "        :return: A list of Document objects\n",
    "        \"\"\"\n",
    "        try:\n",
    "            with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                html = file.read()\n",
    "                soup = BeautifulSoup(html, 'html.parser')\n",
    "                sections = await self.extract_sections(soup)\n",
    "\n",
    "                documents = self.create_documents(sections, file_path)\n",
    "                return documents\n",
    "        except Exception as e:\n",
    "            print(f\"Error scraping {file_path}: {str(e)}\")\n",
    "            return []\n",
    "\n",
    "    async def scrape_files(self, file_paths: List[str]) -> List[Document]:\n",
    "        \"\"\"Scrape a list of files and return a list of Document objects.\n",
    "\n",
    "        This function will scrape each file in the list in parallel using asyncio.\n",
    "        The documents from each file are collected and returned as a single list.\n",
    "\n",
    "        :param file_paths: A list of file paths to scrape\n",
    "        :return: A list of Document objects\n",
    "        \"\"\"\n",
    "        tasks = [self.scrape_file(file_path) for file_path in file_paths]\n",
    "        documents_list = await asyncio.gather(*tasks)\n",
    "        all_documents = [doc for sublist in documents_list for doc in sublist]\n",
    "        return all_documents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "import os\n",
    "\n",
    "# Mount your Google Drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scraper = WebScraper()\n",
    "dir_to_work_with = '/content/drive/MyDrive/api'\n",
    "html_files = []\n",
    "for root, dirs, files in os.walk(dir_to_work_with):\n",
    "    for file in files:\n",
    "        if file.endswith(\".html\"):\n",
    "            html_files.append(os.path.join(root, file))\n",
    "print(\"the html files got from directory and embedding initialized\\n\")\n",
    "\n",
    "print(\"document scrape started\")\n",
    "documents = await scraper.scrape_files(file_paths=html_files)\n",
    "print(\"documents scrape done \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing embeddings and upserting the documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "vector_store = PineconeVectorStore(index=pinecone_manager.index, embedding=embeddings)\n",
    "\n",
    "vector_store.add_documents(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Testing the vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"How does keras handle Layers?\"\n",
    "vector_store.similarity_search_with_relevance_scores(query)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
